・使用するデータセット（fma_small）をダウンロードする。

fmaのリポジトリ（https://github.com/mdeff/fma）のREADME.mdに記載されているリンクからfma_small.zip（7.2 GiB）というデータとfma_metadata.zip(342 MiB)というメタデータをダウンロードする。

ダウンロードしたら、解凍して以下のようなディレクトリ構成にしてまとめておく。
(例)
fma/
   ├ fma_small/
   └ fma_metadata/

※fma_smallにはいくつか問題のあるデータが含まれているので、wiki（https://github.com/mdeff/fma/wiki）を参考に削除しておく。
※wikiのExcerpts shorter than 30s and erroneous audio length metadataという項のList of the 6 shorter tracks in fma_small.zip.にリスト化されているのが問題のデータ。


・ダウンロードしたデータをジャンル毎に分ける。

fma_separate.Rというスクリプトを使ってジャンル毎に分ける。
スクリプトによりfma_small_separatedというフォルダが作られ、８つのジャンルに分別される。
(例)
fma/
   ├ fma_small/
   ├ fma_metadata/
   └ fma_small_separated/
      ├ Rock/
      ├ Hip-Hop/
         ︙


・データをmp3形式からwav形式に変換する。

fma_smallのデータはmp3形式であるが、pythonで扱いづらいのでwav形式に変換しておく。変換にはffmpegを使う。
convMP3toWAV.pyというスクリプトで指定したフォルダ内のmp3ファイルをすべてwav形式に変換することができる。
（上記スクリプトでは変換の際、データ量を小さくするために、変換の際にモノラル化とサンプリングレートを22050hzにダウンサンプリングしている。）


・wavファイルからCQT画像と位相行列を生成する。

wavToCQT.pyというスクリプトで指定したフォルダ内のwavファイルからCQT画像と位相行列を生成することができる。

・CycleGANでトレーニングを行う。

PytorchのCycleGAN（https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix）を使う。

